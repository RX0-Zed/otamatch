import torch
import math
import torch.nn.functional as F
import numpy as np

import torch.distributed as dist
from train_utils import ce_loss


@torch.no_grad()
def distributed_sinkhorn(scores, tau=0.05, sinkhorn_iterations=3):
    Q = torch.exp(scores / tau).t() # Q is K-by-B for consistency with notations from our paper
    B = Q.shape[1] * dist.get_world_size() # number of samples to assign
    K = Q.shape[0] # how many prototypes

    # make the matrix sums to 1
    sum_Q = torch.sum(Q)
    dist.all_reduce(sum_Q)
    Q /= sum_Q

    for it in range(sinkhorn_iterations):
        # normalize each row: total weight per prototype must be 1/K
        sum_of_rows = torch.sum(Q, dim=1, keepdim=True)
        dist.all_reduce(sum_of_rows)
        Q /= sum_of_rows
        Q /= K

        # normalize each column: total weight per sample must be 1/B
        Q /= torch.sum(Q, dim=0, keepdim=True)
        Q /= B

    Q *= B # the colomns must sum to 1 so that Q is an assignment
    return Q.t()


class Get_Scalar:
    def __init__(self, value):
        self.value = value

    def get_value(self, iter):
        return self.value

    def __call__(self, iter):
        return self.value
